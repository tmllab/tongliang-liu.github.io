
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="shortcut icon" href="paper_dragon.ico">
    <link rel="stylesheet" type="text/css" href="style.css" />
    <!-- <link rel="shortcut icon" href="paper_dragon.ico"> -->
    <title>Tongliang Liu's Homepage </title>
    <base href="https://tongliang-liu.github.io/index.html">
    <!-- <base href="./index.html"> -->
    
    <script type="text/javascript" src="//ra.revolvermaps.com/0/0/8.js?i=0gh03rwju0o&amp;m=0&amp;s=170&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33&amp;v0=80" async="async"></script>
    </head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Tongliang Liu</h1><hr>
<td id="layout-menu">
    <div class="menu-item"><a href="index.html" class="current">Home</a></div>
    <div class="menu-item"><a href="news.html">News</a></div>
    <div class="menu-item"><a href="groups.html">Group</a></div>
    <div class="menu-item"><a href="code.html">Codes</a></div>
    <div class="menu-item"><a href="teaching.html">Teaching</a></div>
    <div class="menu-item"><a href="service.html">Service</a></div>
    <div class="menu-item"><a href="publications.html">Publications</a></div>
</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Home</h1><br>
  <!--  <p>[ <a href="#news">News</a>,
        <a href="#interest">Research Interests</a>,
        <a href="#job">Job Experience</a>,
        <a href="#edu">Education</a> ]</p>-->

    <table class="imgtable"><tr valign="center">
        <td><img src="Tongliang-Liu.jpg" alt="Tongliang Liu" border="0" width=140/></td>
        <td align="left">
            <br>
            <p><span style="font-size: 110%"><b>Tongliang Liu</b></span></p>
            <p>
                Lecturer (Assistant Professor) in Machine Learning<br>
                ARC DECRA Fellow<br>
                <a href="https://sydney.edu.au/engineering/about/school-of-computer-science.html" target="_blank">School of Computer Science</a><br>
                <a href="https://www.riken.jp/en/" target="_blank">Facult of Engineering</a><br>
                <a href="https://sydney.edu.au/" target="_blank">The University of Sydney</a>
            </p>
            
                 <p>
                Visiting Scientist<br>
                <a href="https://aip.riken.jp/labs/generic_tech/imperfect_inf_learn/?lang=en" target="_blank">Imperfect Information Learning Team</a><br>
                <a href="https://aip.riken.jp/" target="_blank">RIKEN AIP</a>, Japan<br>
            </p>

            <p>
                Address: Room 315/J12/ 1 Cleveland St, Darlington, NSW 2008, Australia <br>
                E-mail: tongliang.liu [at] sydney.edu.au; tliang.liu [at] gmail.com<br>
                <a href="https://scholar.google.com.au/citations?user=EiLdZ_YAAAAJ&hl=en" target="_blank">[Google Scholar]</a>
                <a href="https://dblp.uni-trier.de/pers/hd/l/Liu:Tongliang" target="_blank">[DBLP]</a>
            </p>
        </td>
    </table>
    <p>
        
            <p>
      I am heading the <a HREF="https://www.tmllab.ai/"> Trustworthy Machine Learning Lab (TML Lab)</a> at the University of Sydney.
   </p>
        
    <p>
    <pp>  
     We are always looking for highly-motivated undergraduate and postgraduate students to join our group. Scholarships are available!
   </pp>
   </p>
    
<!--      <p>
         <pp>
    A postdoc position is available.          
    </pp>
          </p> -->
    
      <p>
      A few visiting positions in machine learning and computer vision are available.
      </p>
    
      <p>

     Some information about scholarships: <ul>
     <li>For both domestic and international PhD students, you can apply for <a HREF="https://sydney.edu.au/scholarships/international/postgraduate-research.html">the RTP scholarship or the Faculty scholarship.</a> There is no specific deadline for the application. I would help you assess the probability to get a scholarship.</li> 
     <li>For international PhD students, you can also consider applying for some <a href="https://sydney.edu.au/scholarships/international/postgraduate-research/general.html"> general scholarships </a>. There are strict deadlines for the scholarships. For example, the <a href="https://sydney.edu.au/scholarships/e/china-scholarship-council-research-programs-scholarship.html"> CSC-USYD</a> scholarship has a deadline normally in December.</li>
     <li>For all students, there are also many other scholarships to explore. I am happy to supervise outstanding students who have passion in research.</li>
      </ul>
    <div>
        <h2><hr><a name="news"></a>Research Interests</h2>
        My research interests lie in providing mathematical and theoretical foundations to justify and understand (deep) machine learning models and designing efficient learning algorithms for problems in computer vision and data mining, with a particular emphasis on 
   <ul>
        <li><p>Learning with label noise</p></li>
               <li><p>Deep transfer learning</p></li>
        <li><p>Deep adversarial learning </p></li>
        <li><p>Deep unsupervised learning </p></li>
        <li><p>Image processing </p></li>
        <li><p>Statistical deep learning theory </p></li>
       </ul>
     <div>
        <h2><hr><a name="news"></a>Top News</h2>
        <ul> 

            <li><p>03/2021, we are organising (I am a co-chair) <a href="https://wsl-workshop.github.io/ijcai21.html"> the Weakly Supervised Representation Learning (WSRL) workshop </a> at <a href="https://ijcai-21.org/">IJCAI 2021</a>. Welcome to contribute! </p></li>
        
            <li><p>03/2021, I accepted the invitation to serve as an Area Chair for NeurIPS 2021.  </p></li>

            <li><p>02/2021, we are organising (I am a co-chair) <a href="https://ajml2021.github.io/"> the first Australia-Japan Workshop on Machine Learning</a>.  </p></li>
                   
            <li><p>02/2021, I was an Expert Reviewer for ICML 2021.  </p></li>
            
            <li><p>11/2020, I accepted the Early Career Researcher Award – Honourable Mention, Australian Pattern Recognition Society (APRS).  </p></li>
            
            <li><p>10/2020, I was among the top 10% of high-scoring reviewers of NeurIPS 2020.  </p></li>
           

            <li><p>10/2020, Workshop, <a href="https://wsl-workshop.github.io/acml20.html">Weakly-supervised Representation Learning</a> at <a href="http://www.acml-conf.org/2020/">ACML 2020.</a> </p></li>
                        
            <li><p>9/2020, I was named in the Early Achievers Leaderboard by <a href="https://specialreports.theaustralian.com.au/1540291/27/">The Asutralian</a>.  </p></li>
            
            <li><p>8/2020, I accepted the invitation to serve as an Area Chair for IJCAI 2021.  </p></li>

            <li><p>4/2020, Invited Talk, “On the Anchor Point of Label-noise Learning”, VALSE (Vision And Learning SEminar), Online.  </p></li>

            <li><p>4/2020, I was appointed as a visiting scientist with RIKEN, Japan.  </p></li>
                
            
            <li><p>1/2020, Invited Talk, “Estimating Transition Matrix for Label-noise Learning”, Peking University, China. </p></li>
                                 
           
            <li><p>12/2019, Workshop, <a href="https://wsl-workshop.github.io/sdm20">Weakly-supervised and Unsupervised Learning Workshop</a> at the <a href="https://www.siam.org/conferences/cm/conference/sdm20">SIAM International Conference on Data Mining (SDM2020).</a> </p></li>

            <li><p>12/2018, Workshop, <a href="http://www.cis.umassd.edu/~mshao/BDTL2018/index.html">3rd International Workshop on Big Data Transfer Learning (BDTL)</a> at the <a href="https://cci.drexel.edu/bigdata/bigdata2018/">IEEE International Conference on Big Data.</a></p></li>

            <li><p>11/2017, Tutorial Talk, <a href="http://dicta2017.dictaconference.org/tutorial.html">Learning with Label Noise</a> at the <a href="http://dicta2017.dictaconference.org/"> International Conference on Digital Image Computing: Techniques and Applications (DICTA).</a></p></li>

         </ul>
         See more previous news <a href="news.html">here</a>.
</div>
          <div>
        <h2><hr><a name="news"></a>Selelcted Publications on Learning with Noise Labels</h2>
              <ul>
                       
                  
           <li><p>
           A Second-Order Approach to Learning with Instance-Dependent Label Noise. <br>
           Z. Zhu, <b>T. Liu</b>, and Y. Liu.<br>
           In <a href="http://cvpr2021.thecvf.com/"> CVPR</a>, 2021.
           </p></li>
                  
            <li><p>
            Robust early-learning: Hindering the memorization of noisy labels. [<A HREF="https://openreview.net/forum?id=Eql5b1_hTE4">PDF</A>]<br>
            X. Xia, <b>T. Liu</b>, B. Han, C. Gong, N. Wang, Z. Ge, and Y. Chang.<br>
            In <a href="https://iclr.cc/Conferences/2021"> ICLR</a>, 2021.
            </p></li>

             <li><p>
            Part-dependent Label Noise: Towards Instance-dependent Label Noise. <br>
            X. Xia, <b>T. Liu</b>, B. Han, N. Wang, M. Gong, H. Liu, G. Niu, D. Tao, and M. Sugiyama.<br>
            In <a href="https://nips.cc/"> NeurIPS</a>, 2020.
            </p></li>
           
                  
            <li><p>
            Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning. <br>
            Y. Yao, <b>T. Liu</b>, B. Han, M. Gong, J. Deng, G. Niu, and M. Sugiyama.<br>
            In <a href="https://nips.cc/"> NeurIPS</a>, 2020.
            </p></li>
                  

             <li><p>
            Sub-center ArcFace: Boosting Face Recognition by Large-scale Noisy Web Faces. <br>
            J. Deng, J. Guo, <b>T. Liu</b>, M. Gong, and S. Zafeiriou.<br>
            In <a href="https://eccv2020.eu/"> ECCV</a>, 2020.
            </p></li>
            
            
             <li><p>
            Learning with Bounded Instance-and Label-dependent Label Noise. <br>
            J. Cheng, <b>T. Liu</b>, K. Rao, and D. Tao.<br>
            In <a href="https://icml.cc/"> ICML</a>, 2020.
            </p></li>
            
            
            <li><p>
            Are Anchor Points Really Indispensable in Label-Noise Learning? [<A HREF="https://papers.nips.cc/paper/8908-are-anchor-points-really-indispensable-in-label-noise-learning.pdf">PDF</A>]<br>
            X. Xia, <b>T. Liu</b>, N. Wang, B. Han, C. Gong, G. Niu, and M. Sugiyama.<br>
            In <a href="https://nips.cc/">NeurIPS</a>, 2019.
            </p></li>
                  

                                    
            <li><p>
            Learning with Biased Complementary Labels. [<A HREF="https://eccv2018.org/openaccess/content_ECCV_2018/papers/Xiyu_Yu_Learning_with_Biased_ECCV_2018_paper.pdf">PDF</A>]<br>
            X. Yu, <b>T. Liu</b>, M. Gong, and D. Tao.<br>
            In <a href="https://eccv2018.org/"> ECCV</a>, 2018.
            </p></li>
                  
                  
                                 
             <li><p>
            Classification with Noisy Labels by Importance Reweighting. [<A HREF="https://arxiv.org/pdf/1411.7718.pdf">PDF</A>]<br>
            <b>T. Liu</b> and D. Tao.<br>
            <b><i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i></b>, 38(3): 447-461, 2015.<br/>
            </p></li>
                  
                  
                  
              </ul>
</div>
        
            
    <div>
        <h2><a name="news"></a>Selelcted Publications on Transfer Learning</h2>
              <ul>
             
                  <li><p>
            Heterogeneous Graph Attention Network for Unsupervised Multiple-Target Domain Adaptation.[<A HREF="https://ieeexplore.ieee.org/document/9204804">Paper</A>]<br>
           X. Yang, C. Deng, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, accepted.<br/>
            </p></li>  
                  
                  
            <li><p>
            Domain Generalization via Entropy Regularization. [<A HREF="https://papers.nips.cc/paper/2020/file/b98249b38337c5088bbc660d8f872d6a-Paper.pdf">PDF</A>]<br>
            S. Zhao, M. Gong, <b>T. Liu</b>,  H. Fu, and D. Tao.<br>
            In <a href="https://nips.cc/"> NeurIPS</a>, 2020.
            </p></li>
                  
            
            <li><p>
            Label-Noise Robust Domain Adaptation.<br>
            X. Yu, <b>T. Liu</b>, M. Gong, K. Zhang, K. Batmanghelich, and D. Tao.<br>
             In <a href="https://icml.cc/"> ICML</a>, 2020.
            </p></li>
                  
             <li><p>
            Transferring Knowledge Fragments for Learning Distance Metric from A Heterogeneous Domain. [<A HREF="https://ieeexplore.ieee.org/abstract/document/8333749">Paper</A>]<br>
            Y. Luo, Y. Wen, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 41(4): 1013-1026, 2019.<br/>
            </p></li>
            
                  
            <li><p>
            LTF: A Label Transformation Framework for Correcting Label Shift. [<A HREF="https://proceedings.icml.cc/static/paper_files/icml/2020/1262-Paper.pdf">PDF</A>]<br>
            J. Guo, M. Gong, <b>T. Liu</b>, K. Zhang, and D. Tao.<br>
             In <a href="https://icml.cc/"> ICML</a>, 2020.
            </p></li>
                  
            <li><p>
            Deep Domain Generalization via Conditional Invariant Adversarial Networks. [<A HREF="http://openaccess.thecvf.com/content_ECCV_2018/papers/Ya_Li_Deep_Domain_Generalization_ECCV_2018_paper.pdf">PDF</A>]<br>
            Y. Li, X. Tian, M. Gong, Y. Liu, <b>T. Liu</b>, K. Zhang, and D. Tao.<br>
            In <a href="https://eccv2018.org/"> ECCV</a>, 2018.
            </p></li>
                  
            <li><p>
            Online Heterogeneous Transfer Metric Learning. [<A HREF="https://www.ijcai.org/proceedings/2018/0350.pdf">PDF</A>]<br>
            Y. Luo, <b>T. Liu</b>, Y. Wen, and D. Tao.<br>
            In <a href="https://ijcai-18.org/">IJCAI</a>, 2018.
            </p></li>

            <li><p>
            Domain Adaptation with Conditional Transferable Components. [<A HREF="http://proceedings.mlr.press/v48/gong16.pdf">PDF</A>]<br>
            M. Gong, K. Zhang, <b>T. Liu</b>, D. Tao, C. Glymour, and B. Schölkopf.<br>
            In <a href="http://icml.cc/2016/"> ICML</a></i>, 2106.
            </p></li>
                  
                  
              </ul>
</div>
    
        
        <div>
        <h2><a name="news"></a>Selelcted Publications on Statistical (Deep) Learning Theory</h2>
              <ul>
            
            <li><p>
            Why ResNet Works? Residuals Generalize. [<A HREF="https://arxiv.org/abs/1904.01367">PDF</A>]<br>
            F. He, <b>T. Liu</b>, and D. Tao.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a></i>, 31(12): 5349-5362, 2020.<br/>
            </p></li>   
                  
                  
            <li><p>
            Control Batch Size and Learning Rate to Generalize Well: Theoretical and Empirical Evidence. [<A HREF="https://papers.nips.cc/paper/8398-control-batch-size-and-learning-rate-to-generalize-well-theoretical-and-empirical-evidence.pdf">PDF</A>]<br>
            F. He, <b>T. Liu</b>, and D. Tao.<br>
            In <a href="https://nips.cc/">NeurIPS</a></i>, 2019.
            </p></li>
        
        
            <li><p>
            Algorithmic Stability and Hypothesis Complexity. [<A HREF="http://proceedings.mlr.press/v70/liu17c/liu17c.pdf">PDF</A>]<br>
            <b>T. Liu</b>, G. Lugosi, G. Neu and D. Tao.<br>
            In <a href="https://2017.icml.cc/"> ICML </a>, 2017.
            </p></li>
               
   
            <li><p>
            Understanding How Feature Structure Transfers in Transfer Learning. [<A HREF="https://www.ijcai.org/Proceedings/2017/0329.pdf">PDF</A>]<br>
            <b>T. Liu</b>, Q. Yang, and D. Tao.<br>
            In <a href="https://ijcai-17.org/"> IJCAI</a>, 2017.
            </p></li>
                  
            <li><p>
            Algorithm-Dependent Generalization Bounds for Multi-Task Learning. [<A HREF="https://ieeexplore.ieee.org/document/7437460">Paper</A>]<br>
            <b>T. Liu</b>, D. Tao, M. Song, and S. J. Maybank.<br>
            <i><a target="_blank" href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a></i>, 39(2): 227-241, 2017.<br/>
            </p></li>
        
            <li><p>
            Dimensionality-Dependent Generalization Bounds for k-Dimensional Coding Schemes.</font> [<A HREF="https://arxiv.org/pdf/1601.00238.pdf">PDF</A>] <br>
            <b>T. Liu</b>, D. Tao, and D. Xu.<br>
            <i><a target="_blank" href="http://www.mitpressjournals.org/loi/neco">NECO</a></i>, 28(10): 2213-2249, 2016.<br/>
            </p></li>

                  
                  
              </ul>
See the full list <a href="publications.html">here</a>.
</div>



        
     <div>
    <h2><hr><a name="sponsors"></a>Sponsors</h2>
    <img src="arc sponsor.png" alt="Australian Research Council" width="200" height="50"/>
    <img src="usyd sponsor.png" alt="Usyd" width="150" height="50"/>
    </div>
        
<div>

      <h2 style="font-family: Helvetica,Arial,sans-serif;"><o:p>&nbsp;</o:p></h2>
      <p>
<!--         Last Update: 5/2019.<br> -->
    <script src="//t1.extreme-dm.com/f.js" id="eXF-tliu9526-0" async defer></script>

   
</p>
</div>

</td>
</tr>
</table>
</body>
</html>
